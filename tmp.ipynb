{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Python - tfrecord Library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import math\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import itertools\n",
    "import torch\n",
    "from tfrecord.torch.dataset import TFRecordDataset\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from waymo_open_dataset.metrics.ops import py_metrics_ops\n",
    "from waymo_open_dataset.metrics.python import config_util_py as config_util\n",
    "from waymo_open_dataset.protos import motion_metrics_pb2\n",
    "\n",
    "# Example field definition\n",
    "roadgraph_features = {\n",
    "    'roadgraph_samples/dir':\n",
    "        'float',\n",
    "    'roadgraph_samples/id':\n",
    "        'int',\n",
    "    'roadgraph_samples/type':\n",
    "        'int',\n",
    "    'roadgraph_samples/valid':\n",
    "        'int',\n",
    "    'roadgraph_samples/xyz':\n",
    "        'float',\n",
    "}\n",
    "\n",
    "# Features of other agents.\n",
    "state_features = {\n",
    "    'state/id':\n",
    "        'float',\n",
    "    'state/type':\n",
    "        'float',\n",
    "    'state/is_sdc':\n",
    "        'int',\n",
    "    'state/tracks_to_predict':\n",
    "        'int',\n",
    "    'state/current/bbox_yaw':\n",
    "        'float',\n",
    "    'state/current/height':\n",
    "        'float',\n",
    "    'state/current/length':\n",
    "        'float',\n",
    "    'state/current/timestamp_micros':\n",
    "        'int',\n",
    "    'state/current/valid':\n",
    "        'int',\n",
    "    'state/current/vel_yaw':\n",
    "        'float',\n",
    "    'state/current/velocity_x':\n",
    "        'float',\n",
    "    'state/current/velocity_y':\n",
    "        'float',\n",
    "    'state/current/width':\n",
    "        'float',\n",
    "    'state/current/x':\n",
    "        'float',\n",
    "    'state/current/y':\n",
    "        'float',\n",
    "    'state/current/z':\n",
    "        'float',\n",
    "    'state/future/bbox_yaw':\n",
    "        'float',\n",
    "    'state/future/height':\n",
    "        'float',\n",
    "    'state/future/length':\n",
    "        'float',\n",
    "    'state/future/timestamp_micros':\n",
    "        'int',\n",
    "    'state/future/valid':\n",
    "        'int',\n",
    "    'state/future/vel_yaw':\n",
    "        'float',\n",
    "    'state/future/velocity_x':\n",
    "        'float',\n",
    "    'state/future/velocity_y':\n",
    "        'float',\n",
    "    'state/future/width':\n",
    "        'float',\n",
    "    'state/future/x':\n",
    "        'float',\n",
    "    'state/future/y':\n",
    "        'float',\n",
    "    'state/future/z':\n",
    "        'float',\n",
    "    'state/past/bbox_yaw':\n",
    "        'float',\n",
    "    'state/past/height':\n",
    "        'float',\n",
    "    'state/past/length':\n",
    "        'float',\n",
    "    'state/past/timestamp_micros':\n",
    "        'int',\n",
    "    'state/past/valid':\n",
    "        'int',\n",
    "    'state/past/vel_yaw':\n",
    "        'float',\n",
    "    'state/past/velocity_x':\n",
    "        'float',\n",
    "    'state/past/velocity_y':\n",
    "        'float',\n",
    "    'state/past/width':\n",
    "        'float',\n",
    "    'state/past/x':\n",
    "        'float',\n",
    "    'state/past/y':\n",
    "        'float',\n",
    "    'state/past/z':\n",
    "        'float',\n",
    "}\n",
    "\n",
    "traffic_light_features = {\n",
    "    'traffic_light_state/current/state':\n",
    "        'int',\n",
    "    'traffic_light_state/current/valid':\n",
    "        'int',\n",
    "    'traffic_light_state/current/x':\n",
    "        'float',\n",
    "    'traffic_light_state/current/y':\n",
    "        'float',\n",
    "    'traffic_light_state/current/z':\n",
    "        'float',\n",
    "    'traffic_light_state/past/state':\n",
    "        'int',\n",
    "    'traffic_light_state/past/valid':\n",
    "        'int',\n",
    "    'traffic_light_state/past/x':\n",
    "        'float',\n",
    "    'traffic_light_state/past/y':\n",
    "        'float',\n",
    "    'traffic_light_state/past/z':\n",
    "        'float',\n",
    "    'traffic_light_state/future/state':\n",
    "        'int',\n",
    "    'traffic_light_state/future/valid':\n",
    "        'int',\n",
    "    'traffic_light_state/future/x':\n",
    "        'float',\n",
    "    'traffic_light_state/future/y':\n",
    "        'float',\n",
    "    'traffic_light_state/future/z':\n",
    "        'float',\n",
    "}\n",
    "\n",
    "features_description = {}\n",
    "features_description.update(roadgraph_features)\n",
    "features_description.update(state_features)\n",
    "features_description.update(traffic_light_features)\n",
    "\n",
    "\n",
    "# Example field definition\n",
    "roadgraph_transforms = {\n",
    "    'roadgraph_samples/dir':\n",
    "        lambda x : np.reshape(x,(20000,3)),\n",
    "    'roadgraph_samples/id':\n",
    "        lambda x : np.reshape(x,(20000,1)),\n",
    "    'roadgraph_samples/type':\n",
    "        lambda x : np.reshape(x,(20000,1)),\n",
    "    'roadgraph_samples/valid':\n",
    "        lambda x : np.reshape(x,(20000,1)),\n",
    "    'roadgraph_samples/xyz':\n",
    "        lambda x : np.reshape(x,(20000,3)),\n",
    "}\n",
    "\n",
    "# Features of other agents.\n",
    "state_transforms = {\n",
    "    'state/id':\n",
    "        lambda x : np.reshape(x,(128,)),\n",
    "    'state/type':\n",
    "        lambda x : np.reshape(x,(128,)),\n",
    "    'state/is_sdc':\n",
    "        lambda x : np.reshape(x,(128,)),\n",
    "    'state/tracks_to_predict':\n",
    "        lambda x : np.reshape(x,(128,)),\n",
    "    'state/current/bbox_yaw':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/height':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/length':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/timestamp_micros':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/valid':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/vel_yaw':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/velocity_x':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/velocity_y':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/width':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/x':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/y':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/current/z':\n",
    "        lambda x : np.reshape(x,(128,1)),\n",
    "    'state/future/bbox_yaw':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/height':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/length':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/timestamp_micros':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/valid':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/vel_yaw':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/velocity_x':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/velocity_y':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/width':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/x':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/y':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/future/z':\n",
    "        lambda x : np.reshape(x,(128,80)),\n",
    "    'state/past/bbox_yaw':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/height':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/length':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/timestamp_micros':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/valid':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/vel_yaw':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/velocity_x':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/velocity_y':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/width':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/x':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/y':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "    'state/past/z':\n",
    "        lambda x : np.reshape(x,(128,10)),\n",
    "}\n",
    "\n",
    "traffic_light_transforms = {\n",
    "    'traffic_light_state/current/state':\n",
    "        lambda x : np.reshape(x,(1,16)),\n",
    "    'traffic_light_state/current/valid':\n",
    "        lambda x : np.reshape(x,(1,16)),\n",
    "    'traffic_light_state/current/x':\n",
    "        lambda x : np.reshape(x,(1,16)),\n",
    "    'traffic_light_state/current/y':\n",
    "        lambda x : np.reshape(x,(1,16)),\n",
    "    'traffic_light_state/current/z':\n",
    "        lambda x : np.reshape(x,(1,16)),\n",
    "    'traffic_light_state/past/state':\n",
    "        lambda x : np.reshape(x,(10,16)),\n",
    "    'traffic_light_state/past/valid':\n",
    "        lambda x : np.reshape(x,(10,16)),\n",
    "    'traffic_light_state/past/x':\n",
    "        lambda x : np.reshape(x,(10,16)),\n",
    "    'traffic_light_state/past/y':\n",
    "        lambda x : np.reshape(x,(10,16)),\n",
    "    'traffic_light_state/past/z':\n",
    "        lambda x : np.reshape(x,(10,16)),\n",
    "    'traffic_light_state/future/state':\n",
    "        lambda x : np.reshape(x,(80,16)),\n",
    "    'traffic_light_state/future/valid':\n",
    "        lambda x : np.reshape(x,(80,16)),\n",
    "    'traffic_light_state/future/x':\n",
    "        lambda x : np.reshape(x,(80,16)),\n",
    "    'traffic_light_state/future/y':\n",
    "        lambda x : np.reshape(x,(80,16)),\n",
    "    'traffic_light_state/future/z':\n",
    "        lambda x : np.reshape(x,(80,16)),\n",
    "}\n",
    "\n",
    "features_transforms = {}\n",
    "features_transforms.update(roadgraph_transforms)\n",
    "features_transforms.update(state_transforms)\n",
    "features_transforms.update(traffic_light_transforms)\n",
    "\n",
    "features_transforms = {}\n",
    "features_transforms.update(roadgraph_transforms)\n",
    "features_transforms.update(state_transforms)\n",
    "features_transforms.update(traffic_light_transforms)\n",
    "\n",
    "def transform_func(feature):\n",
    "    transform = features_transforms\n",
    "    keys = transform.keys()\n",
    "    for key in keys:\n",
    "        func = transform[key]\n",
    "        feat = feature[key]\n",
    "        feature[key] = func(feat)\n",
    "    return feature\n",
    "\n",
    "\n",
    "FILENAME = '/home/user/Projects/scene_transformer/data/tfrecords/uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000'\n",
    "\n",
    "tfrecord_dataset = TFRecordDataset(FILENAME, index_path=None, description=features_description, transform=transform_func)\n",
    "data0 = next(iter(tfrecord_dataset))\n",
    "# print(parsed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from tfrecord.torch.dataset import MultiTFRecordDataset\n",
    "\n",
    "tfrecord_pattern = 'data/tfrecords/{}'\n",
    "index_pattern = 'data/idxs/{}'\n",
    "splits = {\n",
    "    \"uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000\": 1.0\n",
    "}\n",
    "tfrecord_datasets = MultiTFRecordDataset(tfrecord_pattern, index_pattern, splits, description=features_description, transform=transform_func)\n",
    "data0 = next(iter(tfrecord_datasets))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "GS = 1400\n",
    "\n",
    "past_states_batch = np.array([]).reshape(-1,10,9)\n",
    "past_states_valid_batch = np.array([]).reshape(-1,10)\n",
    "current_states_batch = np.array([]).reshape(-1,1,9)\n",
    "current_states_valid_batch = np.array([]).reshape(-1,1)\n",
    "future_states_batch = np.array([]).reshape(-1,80,9)\n",
    "future_states_valid_batch = np.array([]).reshape(-1,80)\n",
    "states_batch = np.array([]).reshape(-1,91,9)\n",
    "\n",
    "roadgraph_feat_batch = np.array([]).reshape(-1,91,6)\n",
    "\n",
    "traffic_light_feat_batch = np.array([]).reshape(-1,91,3)\n",
    "traffic_light_valid_batch = np.array([]).reshape(-1,91)\n",
    "\n",
    "num_agents = np.array([])\n",
    "\n",
    "batch = [data0]\n",
    "for data in batch:\n",
    "    # State of Agents\n",
    "    past_states = np.stack((data['state/past/x'],data['state/past/y'],data['state/past/bbox_yaw'],\n",
    "                                data['state/past/velocity_x'],data['state/past/velocity_y'],data['state/past/vel_yaw'],\n",
    "                                    data['state/past/width'],data['state/past/height'],data['state/past/timestamp_micros']), axis=-1)\n",
    "    past_states_valid = data['state/past/valid'] > 0.\n",
    "    current_states = np.stack((data['state/current/x'],data['state/current/y'],data['state/current/bbox_yaw'],\n",
    "                                data['state/current/velocity_x'],data['state/current/velocity_y'],data['state/current/vel_yaw'],\n",
    "                                    data['state/current/width'],data['state/current/height'],data['state/current/timestamp_micros']), axis=-1)\n",
    "    current_states_valid = data['state/current/valid'] > 0.\n",
    "    future_states = np.stack((data['state/future/x'],data['state/future/y'],data['state/future/bbox_yaw'],\n",
    "                                data['state/future/velocity_x'],data['state/future/velocity_y'],data['state/future/vel_yaw'],\n",
    "                                    data['state/future/width'],data['state/future/height'],data['state/future/timestamp_micros']), axis=-1)\n",
    "    future_states_valid = data['state/future/valid'] > 0.\n",
    "\n",
    "    states_feat = np.concatenate((past_states,current_states,future_states),axis=1)\n",
    "    states_valid = np.concatenate((past_states_valid,current_states_valid,future_states_valid),axis=1)\n",
    "    states_any_mask = np.sum(states_valid,axis=1) > 0\n",
    "    states_feat = states_feat[states_any_mask]\n",
    "\n",
    "    num_agents = np.append(num_agents, len(states_feat))\n",
    "    \n",
    "    # Static Road Graph\n",
    "    roadgraph_feat = np.concatenate((data['roadgraph_samples/id'], data['roadgraph_samples/type'], \n",
    "                                        data['roadgraph_samples/xyz'][:,:2], data['roadgraph_samples/dir'][:,:2]), axis=-1)\n",
    "    roadgraph_valid = data['roadgraph_samples/valid'] > 0.\n",
    "    valid_num = roadgraph_valid.sum()\n",
    "    if valid_num > GS:\n",
    "        roadgraph_feat = roadgraph_feat[roadgraph_valid[:,0]]\n",
    "        spacing = valid_num // GS\n",
    "        roadgraph_feat = roadgraph_feat[::spacing, :]\n",
    "        remove_num = len(roadgraph_feat) - GS\n",
    "        roadgraph_mask2 = np.full(len(roadgraph_feat), True)\n",
    "        idx_remove = np.random.randint(len(roadgraph_feat), size=remove_num)\n",
    "        roadgraph_mask2[idx_remove] = False\n",
    "        roadgraph_feat = roadgraph_feat[roadgraph_mask2]\n",
    "    else:\n",
    "        roadgraph_feat = roadgraph_feat[:GS,:]\n",
    "        # (Optional) : construct roadgraph valid\n",
    "\n",
    "    roadgraph_feat = np.repeat(roadgraph_feat[:,np.newaxis,:],91,axis=1)\n",
    "\n",
    "    # Dynamic Road Graph\n",
    "    traffic_light_states_past = np.stack((data['traffic_light_state/past/state'].T,data['traffic_light_state/past/x'].T,data['traffic_light_state/past/y'].T),axis=-1)\n",
    "    traffic_light_valid_past = data['traffic_light_state/past/valid'].T > 0.\n",
    "    traffic_light_states_current = np.stack((data['traffic_light_state/current/state'].T,data['traffic_light_state/current/x'].T,data['traffic_light_state/current/y'].T),axis=-1)\n",
    "    traffic_light_valid_current = data['traffic_light_state/current/valid'].T > 0.\n",
    "    traffic_light_states_future = np.stack((data['traffic_light_state/future/state'].T,data['traffic_light_state/future/x'].T,data['traffic_light_state/future/y'].T),axis=-1)\n",
    "    traffic_light_valid_future = data['traffic_light_state/future/valid'].T > 0.\n",
    "\n",
    "    traffic_light_feat = np.concatenate((traffic_light_states_past,traffic_light_states_current,traffic_light_states_future),axis=1)\n",
    "    traffic_light_valid = np.concatenate((traffic_light_valid_past,traffic_light_valid_current,traffic_light_valid_future),axis=1)\n",
    "\n",
    "    # Concat across batch\n",
    "    past_states_batch = np.concatenate((past_states_batch, past_states), axis=0)\n",
    "    past_states_valid_batch = np.concatenate((past_states_valid_batch, past_states_valid), axis=0)\n",
    "    current_states_batch = np.concatenate((current_states_batch, current_states), axis=0)\n",
    "    current_states_valid_batch = np.concatenate((current_states_valid_batch, current_states_valid), axis=0)\n",
    "    future_states_batch = np.concatenate((future_states_batch, future_states), axis=0)\n",
    "    future_states_valid_batch = np.concatenate((future_states_valid_batch, future_states_valid), axis=0)\n",
    "\n",
    "    states_batch = np.concatenate((states_batch,states_feat), axis=0)\n",
    "\n",
    "    roadgraph_feat_batch = np.concatenate((roadgraph_feat_batch, roadgraph_feat), axis=0)\n",
    "\n",
    "    traffic_light_feat_batch = np.concatenate((traffic_light_feat_batch, traffic_light_feat), axis=0)\n",
    "    traffic_light_valid_batch = np.concatenate((traffic_light_valid_batch, traffic_light_valid), axis=0)\n",
    "\n",
    "num_agents_accum = np.cumsum(np.insert(num_agents,0,0)).astype(np.int64)\n",
    "agents_batch_mask = np.zeros((num_agents_accum[-1],num_agents_accum[-1]))\n",
    "\n",
    "for i in range(len(num_agents)):\n",
    "    agents_batch_mask[num_agents_accum[i]:num_agents_accum[i+1], num_agents_accum[i]:num_agents_accum[i+1]] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "states_feat.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(26, 91, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import math\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from waymo_open_dataset.metrics.ops import py_metrics_ops\n",
    "from waymo_open_dataset.metrics.python import config_util_py as config_util\n",
    "from waymo_open_dataset.protos import motion_metrics_pb2\n",
    "\n",
    "# Example field definition\n",
    "roadgraph_features = {\n",
    "    'roadgraph_samples/dir':\n",
    "        tf.io.FixedLenFeature([20000, 3], tf.float32, default_value=None),\n",
    "    'roadgraph_samples/id':\n",
    "        tf.io.FixedLenFeature([20000, 1], tf.int64, default_value=None),\n",
    "    'roadgraph_samples/type':\n",
    "        tf.io.FixedLenFeature([20000, 1], tf.int64, default_value=None),\n",
    "    'roadgraph_samples/valid':\n",
    "        tf.io.FixedLenFeature([20000, 1], tf.int64, default_value=None),\n",
    "    'roadgraph_samples/xyz':\n",
    "        tf.io.FixedLenFeature([20000, 3], tf.float32, default_value=None),\n",
    "}\n",
    "\n",
    "# Features of other agents.\n",
    "state_features = {\n",
    "    'state/id':\n",
    "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "    'state/type':\n",
    "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "    'state/is_sdc':\n",
    "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
    "    'state/tracks_to_predict':\n",
    "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
    "    'state/current/bbox_yaw':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/height':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/length':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/timestamp_micros':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
    "    'state/current/valid':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
    "    'state/current/vel_yaw':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/velocity_x':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/velocity_y':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/width':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/x':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/y':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/z':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/future/bbox_yaw':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/height':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/length':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/timestamp_micros':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
    "    'state/future/valid':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
    "    'state/future/vel_yaw':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/velocity_x':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/velocity_y':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/width':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/x':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/y':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/z':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/past/bbox_yaw':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/height':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/length':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/timestamp_micros':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
    "    'state/past/valid':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
    "    'state/past/vel_yaw':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/velocity_x':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/velocity_y':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/width':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/x':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/y':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/z':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "}\n",
    "\n",
    "traffic_light_features = {\n",
    "    'traffic_light_state/current/state':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/current/valid':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/current/x':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/current/y':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/current/z':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/past/state':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/past/valid':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/past/x':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/past/y':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/past/z':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "}\n",
    "\n",
    "features_description = {}\n",
    "features_description.update(roadgraph_features)\n",
    "features_description.update(state_features)\n",
    "features_description.update(traffic_light_features)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
    "data = next(dataset.as_numpy_iterator())\n",
    "tensorflow_data = tf.io.parse_single_example(data, features_description)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data0\n",
    "tensorflow_data\n",
    "\n",
    "assert data0.keys() == tensorflow_data.keys()\n",
    "for key in data0.keys():\n",
    "    data0_k = data0[key]\n",
    "    tensorflow_data_k = tensorflow_data[key]\n",
    "    # print(key, data0_k, tensorflow_data_k)\n",
    "    assert (np.array(data0_k) == np.array(tensorflow_data_k)).any(), key\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datautil.waymo_dataset import WaymoDataset\n",
    "\n",
    "dataset = WaymoDataset('data')\n",
    "data0 = next(iter(dataset))\n",
    "\n",
    "print(data0.keys())"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "97a78a4e4847bcd3012bc38194af59d45dfe518ac95abf5f0758243f1884d290"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}